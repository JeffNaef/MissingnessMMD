included = logical(B)
)
# Run simulations
for (b in 1:B) {
# Generate bivariate normal data with zero correlation
mu <- c(0, 0)
Sigma <- matrix(c(1, 0, 0, 1), ncol = 2)
data_complete <- as.data.frame(mvrnorm(n, mu = mu, Sigma = Sigma))
names(data_complete) <- c("X1", "X2")
# Create a copy of the data to introduce missingness
data <- data_complete
res<-matrix(NA, nrow=L, ncol=1)
for (l in 1:L){
res[l]<-get_results(data = data[sample(1:nrow(data), size=n, replace=T),])$estimate
}
results$beta_imp[b]<-mean(c(res))
results$se_imp[b]<-var( c(res) )
# Calculate confidence intervals (95%)
results$ci_lower[b] <- results$beta_imp[b] - 1.96 * results$se_imp[b]
results$ci_upper[b] <- results$beta_imp[b] + 1.96 * results$se_imp[b]
# Check if true value (0) is in the confidence interval
results$included[b] <- results$ci_lower[b] <= 0 && 0 <= results$ci_upper[b]
# Optional: print progress
if (b %% 100 == 0) cat("Completed", b, "simulations\n")
}
# Summarize results
coverage_probability <- mean(results$included)
cat("Coverage probability:", coverage_probability, "\n")
results
res
data[sample(1:nrow(data), size=n, replace=T),]
data[sample(1:nrow(data), size=n, replace=T),]
data[sample(1:nrow(data), size=n, replace=T),]
data[sample(1:nrow(data), size=n, replace=T),]
get_results(data = data[sample(1:nrow(data), size=n, replace=T),])$estimate
get_results(data = data[sample(1:nrow(data), size=n, replace=T),])$estimate
get_results(data = data[sample(1:nrow(data), size=n, replace=T),])$estimate
results$beta_imp[b]<- get_results(data = data)$estimate #mean(c(res))
results$beta_imp[b]
mean(c(res))
results$se_imp[b]<-var( c(res)-results$beta_imp[b] )
results$se_imp[b]<-mean( (c(res)-results$beta_imp[b])^2 )
results$se_imp[b]
results$beta_imp[b]
results$beta_imp[b]<- get_results(data = data)$estimate #mean(c(res))
results$se_imp[b]<-mean( (c(res)-results$beta_imp[b])^2 )
# Calculate confidence intervals (95%)
results$ci_lower[b] <- results$beta_imp[b] - 1.96 * results$se_imp[b]
results$ci_upper[b] <- results$beta_imp[b] + 1.96 * results$se_imp[b]
results <- data.frame(
beta_imp = numeric(B),
se_imp = numeric(B),
ci_lower = numeric(B),
ci_upper = numeric(B),
included = logical(B)
)
results$beta_imp[b]<- get_results(data = data)$estimate #mean(c(res))
results$se_imp[b]<-mean( (c(res)-results$beta_imp[b])^2 )
# Calculate confidence intervals (95%)
results$ci_lower[b] <- results$beta_imp[b] - 1.96 * results$se_imp[b]
results$ci_upper[b] <- results$beta_imp[b] + 1.96 * results$se_imp[b]
results$ci_lower[b]
results$ci_upper[b]
results$beta_imp[b]<- get_results(data = data)$estimate #mean(c(res))
results$se_imp[b]<-sqrt(mean( (c(res)-results$beta_imp[b])^2 ))
results$se_imp
results$beta_imp[b]<- get_results(data = data)$estimate #mean(c(res))
results$se_imp[b]<-sqrt(mean( (c(res)-results$beta_imp[b])^2 ))
# Calculate confidence intervals (95%)
results$ci_lower[b] <- results$beta_imp[b] - 1.96 * results$se_imp[b]
results$ci_upper[b] <- results$beta_imp[b] + 1.96 * results$se_imp[b]
ci_upper
results
L<-20
results <- data.frame(
beta_imp = numeric(B),
se_imp = numeric(B),
ci_lower = numeric(B),
ci_upper = numeric(B),
included = logical(B)
)
# Run simulations
for (b in 1:B) {
# Generate bivariate normal data with zero correlation
mu <- c(0, 0)
Sigma <- matrix(c(1, 0, 0, 1), ncol = 2)
data_complete <- as.data.frame(mvrnorm(n, mu = mu, Sigma = Sigma))
names(data_complete) <- c("X1", "X2")
# Create a copy of the data to introduce missingness
data <- data_complete
res<-matrix(NA, nrow=L, ncol=1)
for (l in 1:L){
res[l]<-get_results(data = data[sample(1:nrow(data), size=n, replace=T),])$estimate
}
results$beta_imp[b]<- get_results(data = data)$estimate #mean(c(res))
results$se_imp[b]<-sqrt(mean( (c(res)-results$beta_imp[b])^2 ))
# Calculate confidence intervals (95%)
results$ci_lower[b] <- results$beta_imp[b] - 1.96 * results$se_imp[b]
results$ci_upper[b] <- results$beta_imp[b] + 1.96 * results$se_imp[b]
# Check if true value (0) is in the confidence interval
results$included[b] <- results$ci_lower[b] <= 0 && 0 <= results$ci_upper[b]
# Optional: print progress
if (b %% 100 == 0) cat("Completed", b, "simulations\n")
}
# Summarize results
coverage_probability <- mean(results$included)
cat("Coverage probability:", coverage_probability, "\n")
# Load required packages
library(mice)
library(MASS)  # For multivariate normal distribution
library(miceDRF)
# Set seed for reproducibility
#set.seed(123)
# Simulation parameters
B <- 200       # Number of simulations
n <- 1000        # Sample size per simulation
p_missing <- 0.4  # Probability of setting X1 to NA when X2 > 0
# Initialize results storage
results <- data.frame(
beta_imp = numeric(B),
se_imp = numeric(B),
ci_lower = numeric(B),
ci_upper = numeric(B),
included = logical(B)
)
get_results <- function(data, method="cart"){  # Introduce missingness in X1 when X2 > 0 with probability p_missing
missing_idx <- which(data$X2 > 0)
set_to_na<-missing_idx[ rbinom(n=length(missing_idx), prob=p_missing, size=1)==1 ]
data$X1[set_to_na] <- NA
# Impute missing values using mice with norm.nob method
#imp <- mice(data, method = "norm.nob", m = 5, printFlag = FALSE)
imp <- mice(data, method = method, m = 5, printFlag = FALSE)
#imp <- mice(data, method = "DRF", m = 5, printFlag = FALSE)
# Analyze imputed datasets
fit <- with(imp, lm(X2 ~ X1))
pooled <- pool(fit)
# Extract results
return( list(estimate=summary(pooled)$estimate[2], se= summary(pooled)$std.error[2] ) )
}
b<1-
b<-1
# Generate bivariate normal data with zero correlation
mu <- c(0, 0)
Sigma <- matrix(c(1, 0, 0, 1), ncol = 2)
data_complete <- as.data.frame(mvrnorm(n, mu = mu, Sigma = Sigma))
names(data_complete) <- c("X1", "X2")
# Create a copy of the data to introduce missingness
data <- data_complete
# Introduce missingness in X1 when X2 > 0 with probability p_missing
missing_idx <- which(data$X2 > 0)
set_to_na<-missing_idx[ rbinom(n=length(missing_idx), prob=p_missing, size=1)==1 ]
data$X1[set_to_na] <- NA
res<-get_results(data, method="cart")
res
results$beta_imp[b] <-res$estimate
results$se_imp[b] <- res$se
results
# Load required packages
library(mice)
library(MASS)  # For multivariate normal distribution
library(miceDRF)
# Set seed for reproducibility
#set.seed(123)
# Simulation parameters
B <- 200       # Number of simulations
n <- 1000        # Sample size per simulation
p_missing <- 0.4  # Probability of setting X1 to NA when X2 > 0
# Initialize results storage
results <- data.frame(
beta_imp = numeric(B),
se_imp = numeric(B),
ci_lower = numeric(B),
ci_upper = numeric(B),
included = logical(B)
)
get_results <- function(data, method="cart"){  # Introduce missingness in X1 when X2 > 0 with probability p_missing
missing_idx <- which(data$X2 > 0)
set_to_na<-missing_idx[ rbinom(n=length(missing_idx), prob=p_missing, size=1)==1 ]
data$X1[set_to_na] <- NA
# Impute missing values using mice with norm.nob method
#imp <- mice(data, method = "norm.nob", m = 5, printFlag = FALSE)
imp <- mice(data, method = method, m = 5, printFlag = FALSE)
#imp <- mice(data, method = "DRF", m = 5, printFlag = FALSE)
# Analyze imputed datasets
fit <- with(imp, lm(X2 ~ X1))
pooled <- pool(fit)
# Extract results
return( list(estimate=summary(pooled)$estimate[2], se= summary(pooled)$std.error[2] ) )
}
##Try an additional bootstrap step!
# Run simulations
for (b in 1:B) {
# Generate bivariate normal data with zero correlation
mu <- c(0, 0)
Sigma <- matrix(c(1, 0, 0, 1), ncol = 2)
data_complete <- as.data.frame(mvrnorm(n, mu = mu, Sigma = Sigma))
names(data_complete) <- c("X1", "X2")
# Create a copy of the data to introduce missingness
data <- data_complete
# Introduce missingness in X1 when X2 > 0 with probability p_missing
missing_idx <- which(data$X2 > 0)
set_to_na<-missing_idx[ rbinom(n=length(missing_idx), prob=p_missing, size=1)==1 ]
data$X1[set_to_na] <- NA
# # Impute missing values using mice with norm.nob method
# #imp <- mice(data, method = "norm.nob", m = 5, printFlag = FALSE)
# imp <- mice(data, method = "cart", m = 5, printFlag = FALSE)
# #imp <- mice(data, method = "DRF", m = 5, printFlag = FALSE)
#
# # Analyze imputed datasets
# fit <- with(imp, lm(X2 ~ X1))
# pooled <- pool(fit)
# Extract results
#results$beta_imp[b] <- summary(pooled)$estimate[2]
#results$se_imp[b] <- summary(pooled)$std.error[2]
res<-get_results(data, method="cart")
results$beta_imp[b] <-res$estimate
results$se_imp[b] <- res$se
# Calculate confidence intervals (95%)
results$ci_lower[b] <- results$beta_imp[b] - 1.96 * results$se_imp[b]
results$ci_upper[b] <- results$beta_imp[b] + 1.96 * results$se_imp[b]
# Check if true value (0) is in the confidence interval
results$included[b] <- results$ci_lower[b] <= 0 && 0 <= results$ci_upper[b]
# Optional: print progress
if (b %% 100 == 0) cat("Completed", b, "simulations\n")
}
# Summarize results
coverage_probability_RubinsRules <- mean(results$included)
cat("Coverage probability with Rubins Rules:", coverage_probability, "\n")
# Summarize results
coverage_probability_RubinsRules <- mean(results$included)
cat("Coverage probability with Rubins Rules:", coverage_probability_RubinsRules, "\n")
# Load required packages
library(mice)
library(MASS)  # For multivariate normal distribution
library(miceDRF)
# Set seed for reproducibility
set.seed(123)
# Simulation parameters
B <- 200       # Number of simulations
n <- 1000        # Sample size per simulation
p_missing <- 0.4  # Probability of setting X1 to NA when X2 > 0
# Initialize results storage
results <- data.frame(
beta_imp = numeric(B),
se_imp = numeric(B),
ci_lower = numeric(B),
ci_upper = numeric(B),
included = logical(B)
)
get_results <- function(data, method="cart"){  # Introduce missingness in X1 when X2 > 0 with probability p_missing
missing_idx <- which(data$X2 > 0)
set_to_na<-missing_idx[ rbinom(n=length(missing_idx), prob=p_missing, size=1)==1 ]
data$X1[set_to_na] <- NA
# Impute missing values using mice with norm.nob method
#imp <- mice(data, method = "norm.nob", m = 5, printFlag = FALSE)
imp <- mice(data, method = method, m = 5, printFlag = FALSE)
#imp <- mice(data, method = "DRF", m = 5, printFlag = FALSE)
# Analyze imputed datasets
fit <- with(imp, lm(X2 ~ X1))
pooled <- pool(fit)
# Extract results
return( list(estimate=summary(pooled)$estimate[2], se= summary(pooled)$std.error[2] ) )
}
##Try an additional bootstrap step!
# Run simulations
for (b in 1:B) {
# Generate bivariate normal data with zero correlation
mu <- c(0, 0)
Sigma <- matrix(c(1, 0, 0, 1), ncol = 2)
data_complete <- as.data.frame(mvrnorm(n, mu = mu, Sigma = Sigma))
names(data_complete) <- c("X1", "X2")
# Create a copy of the data to introduce missingness
data <- data_complete
# Introduce missingness in X1 when X2 > 0 with probability p_missing
missing_idx <- which(data$X2 > 0)
set_to_na<-missing_idx[ rbinom(n=length(missing_idx), prob=p_missing, size=1)==1 ]
data$X1[set_to_na] <- NA
# # Impute missing values using mice with norm.nob method
# #imp <- mice(data, method = "norm.nob", m = 5, printFlag = FALSE)
# imp <- mice(data, method = "cart", m = 5, printFlag = FALSE)
# #imp <- mice(data, method = "DRF", m = 5, printFlag = FALSE)
#
# # Analyze imputed datasets
# fit <- with(imp, lm(X2 ~ X1))
# pooled <- pool(fit)
# Extract results
#results$beta_imp[b] <- summary(pooled)$estimate[2]
#results$se_imp[b] <- summary(pooled)$std.error[2]
res<-get_results(data, method="cart")
results$beta_imp[b] <-res$estimate
results$se_imp[b] <- res$se
# Calculate confidence intervals (95%)
results$ci_lower[b] <- results$beta_imp[b] - 1.96 * results$se_imp[b]
results$ci_upper[b] <- results$beta_imp[b] + 1.96 * results$se_imp[b]
# Check if true value (0) is in the confidence interval
results$included[b] <- results$ci_lower[b] <= 0 && 0 <= results$ci_upper[b]
# Optional: print progress
if (b %% 100 == 0) cat("Completed", b, "simulations\n")
}
# Summarize results
coverage_probability_RubinsRules <- mean(results$included)
cat("Coverage probability with Rubins Rules:", coverage_probability_RubinsRules, "\n")
## It seems even for n=1000, there is still an undercoverage with mice-cart!
L<-20
results <- data.frame(
beta_imp = numeric(B),
se_imp = numeric(B),
ci_lower = numeric(B),
ci_upper = numeric(B),
included = logical(B)
)
# Run simulations
for (b in 1:B) {
# Generate bivariate normal data with zero correlation
mu <- c(0, 0)
Sigma <- matrix(c(1, 0, 0, 1), ncol = 2)
data_complete <- as.data.frame(mvrnorm(n, mu = mu, Sigma = Sigma))
names(data_complete) <- c("X1", "X2")
# Create a copy of the data to introduce missingness
data <- data_complete
res<-matrix(NA, nrow=L, ncol=1)
for (l in 1:L){
res[l]<-get_results(data = data[sample(1:nrow(data), size=n, replace=T),])$estimate
}
results$beta_imp[b]<- get_results(data = data)$estimate #mean(c(res))
results$se_imp[b]<-sqrt(mean( (c(res)-results$beta_imp[b])^2 ))
# Calculate confidence intervals (95%)
results$ci_lower[b] <- results$beta_imp[b] - 1.96 * results$se_imp[b]
results$ci_upper[b] <- results$beta_imp[b] + 1.96 * results$se_imp[b]
# Check if true value (0) is in the confidence interval
results$included[b] <- results$ci_lower[b] <= 0 && 0 <= results$ci_upper[b]
# Optional: print progress
if (b %% 100 == 0) cat("Completed", b, "simulations\n")
}
# Summarize results
coverage_probability_Bootstrap <- mean(results$included)
cat("Coverage probability:", coverage_probability_Bootstrap, "\n")
setwd("C:/Users/Jeff/OneDrive/Today/MMDEstimationandMissingnessModelling/Code")
library(devtools)
library(reticulate)
# Step 2: Set up Python environment
# ----------------------------------
# Check if Python is available
py_available()
py_require(c("torch", "torchvision", "torchaudio"))
py_require(c("numpy", "scipy", "matplotlib", "seaborn", "pandas", "scikit-learn"))
# Step 5: Import Python modules and setup
# ----------------------------------------
# Import necessary Python modules
np <- import("numpy")
torch <- import("torch")
sys <- import("sys")
os <- import("os")
matplotlib <- import("matplotlib")
#eigenvalue_pruning<-import("eigenvalue_pruning")
source_python('RobustMeanEstimation-main/Algorithms/eigenvalue_pruning.py')
source_python('RobustMeanEstimation-main/Algorithms/que.py')
source_python('RobustMeanEstimation-main/Algorithms/que_utils.py')
############################################
# =======================================================
# Load required libraries
library(MASS)  # for multivariate normal generation
library(ggplot2)
library(reshape2)
source("mmd_est.R")
source("helpers.R")
# Set parameters
set.seed(123)  # for reproducibility
n <- 500      # total number of samples
d <- 10         # dimension (you can change this)
eps <- 0.2 # contamination fraction (10% contaminated data)
# Clean distribution parameters
mu_clean <- rep(0, d)        # mean vector of zeros
Sigma_clean <- diag(d)       # identity covariance matrix
Xtest<-createdistMNARMCAR(n=5000, d=d, eps=eps, contdist="dirac", c=10)
sum(complete.cases(Xtest))/nrow(Xtest)
#mmd_estown(Xtest, model = "multidim.Gaussian.loc", par2 = 1, control=list(method="SGD", burnin=50, nstep=100))
##expected fraction:
## p2 / (1 - p1 + p2) + (p1 * (1 - p1)) / (d * (1 - p1 + p2)) * (1 - (p1 - p2)^d) / (1 - (p1 - p2))
contaminationlist<-c("rnorm", "rnorm", "rnorm", "dirac","dirac")
parameters<-c(0,1,10,1,10)
methodsp<-c("MMD", "mean", "median")
methodsnp<-c("evpruning", "que")
methods<-c(methodsp,methodsnp)
# Load required packages
library(foreach)
library(doParallel)
# Setup parallel backend for Windows
n_cores <- detectCores() - 1  # Use all cores except 1
cl <- makeCluster(n_cores)
registerDoParallel(cl)
clusterExport(cl, c("contaminationlist", "parameters",
"n", "d", "eps",  # Add your actual variable names here
"createdistMNARMCAR", "mmd_estown"))   # Add your function names here
clusterEvalQ(cl, {
# library(your_package_name)  # Add any packages your functions need
library(mice)
})
B<-50
#for (b in 1:B){
resultsp <- foreach(b = 1:B, .combine ='rbind') %dopar% {
set.seed(b)
cat(b)
methodlist<-list()
for (method in methodsp){
methodlist[[method]] <- matrix(NA, nrow=1, ncol=length(contaminationlist))
colnames(methodlist[[method]]) <- paste0(method, ".", contaminationlist,"_", parameters)
}
for (l in 1:length(contaminationlist)){
contdist <- contaminationlist[l]
cat(contdist)
if (contdist=="rnorm"){
X<-createdistMNARMCAR(n=n, d=d, eps=eps, contdist=contdist, mu=parameters[l])
} else if (contdist=="dirac"){
X<-createdistMNARMCAR(n=n, d=d, eps=eps, contdist=contdist, c=parameters[l])
}
for (method in methodsp){
estimate<-get_estimate(X, method=method)
methodlist[[method]][1,l]<-sqrt(sum(c(estimate)^2))
}
}
res<-data.frame(do.call(cbind,methodlist))
return(res)
#return(list(MSEours=MSEours, MSEmean=MSEmean  ))
}
library(devtools)
library(reticulate)
# Step 2: Set up Python environment
# ----------------------------------
# Check if Python is available
py_available()
py_require(c("torch", "torchvision", "torchaudio"))
py_require(c("numpy", "scipy", "matplotlib", "seaborn", "pandas", "scikit-learn"))
# Step 5: Import Python modules and setup
# ----------------------------------------
# Import necessary Python modules
np <- import("numpy")
torch <- import("torch")
sys <- import("sys")
os <- import("os")
matplotlib <- import("matplotlib")
#eigenvalue_pruning<-import("eigenvalue_pruning")
source_python('RobustMeanEstimation-main/Algorithms/eigenvalue_pruning.py')
source_python('RobustMeanEstimation-main/Algorithms/que.py')
source_python('RobustMeanEstimation-main/Algorithms/que_utils.py')
############################################
# =======================================================
# Load required libraries
library(MASS)  # for multivariate normal generation
library(ggplot2)
library(reshape2)
source("mmd_est.R")
source("helpers.R")
# Set parameters
set.seed(123)  # for reproducibility
n <- 500      # total number of samples
d <- 10         # dimension (you can change this)
eps <- 0.3 # contamination fraction (10% contaminated data)
# Clean distribution parameters
mu_clean <- rep(0, d)        # mean vector of zeros
Sigma_clean <- diag(d)       # identity covariance matrix
Xtest<-createdistMNARMCAR(n=5000, d=d, eps=eps, contdist="dirac", c=10)
sum(complete.cases(Xtest))/nrow(Xtest)
#mmd_estown(Xtest, model = "multidim.Gaussian.loc", par2 = 1, control=list(method="SGD", burnin=50, nstep=100))
##expected fraction:
## p2 / (1 - p1 + p2) + (p1 * (1 - p1)) / (d * (1 - p1 + p2)) * (1 - (p1 - p2)^d) / (1 - (p1 - p2))
contaminationlist<-c("rnorm", "rnorm", "rnorm", "dirac","dirac")
parameters<-c(0,1,10,1,10)
methodsp<-c("MMD", "mean", "median")
methodsnp<-c("evpruning", "que")
methods<-c(methodsp,methodsnp)
# Load required packages
library(foreach)
library(doParallel)
# Setup parallel backend for Windows
n_cores <- detectCores() - 1  # Use all cores except 1
cl <- makeCluster(n_cores)
registerDoParallel(cl)
clusterExport(cl, c("contaminationlist", "parameters",
"n", "d", "eps",  # Add your actual variable names here
"createdistMNARMCAR", "mmd_estown"))   # Add your function names here
clusterEvalQ(cl, {
# library(your_package_name)  # Add any packages your functions need
library(mice)
})
B<-50
#for (b in 1:B){
resultsp <- foreach(b = 1:B, .combine ='rbind') %dopar% {
set.seed(b)
cat(b)
methodlist<-list()
for (method in methodsp){
methodlist[[method]] <- matrix(NA, nrow=1, ncol=length(contaminationlist))
colnames(methodlist[[method]]) <- paste0(method, ".", contaminationlist,"_", parameters)
}
for (l in 1:length(contaminationlist)){
contdist <- contaminationlist[l]
cat(contdist)
if (contdist=="rnorm"){
X<-createdistMNARMCAR(n=n, d=d, eps=eps, contdist=contdist, mu=parameters[l])
} else if (contdist=="dirac"){
X<-createdistMNARMCAR(n=n, d=d, eps=eps, contdist=contdist, c=parameters[l])
}
for (method in methodsp){
estimate<-get_estimate(X, method=method)
methodlist[[method]][1,l]<-sqrt(sum(c(estimate)^2))
}
}
res<-data.frame(do.call(cbind,methodlist))
return(res)
#return(list(MSEours=MSEours, MSEmean=MSEmean  ))
}
